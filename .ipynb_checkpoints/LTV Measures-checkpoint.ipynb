{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'04 April 2019 - Loan Tape.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3ce9ebf64801>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'04 April 2019 - Loan Tape.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'04 April 2019 - Loan Tape.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tape = pd.read_csv('04 April 2019 - Loan Tape.csv')\n",
    "tp = tape.copy()\n",
    "\n",
    "rate = tape['Borrower Rate']\n",
    "la = tape['Loan Amount']\n",
    "fa = tape['Funded Amount']\n",
    "arv = tape['ARV']\n",
    "ltv = tape['LTV']\n",
    "loans = tape['Loan']\n",
    "\n",
    "rate = rate.astype('float64')/100\n",
    "\n",
    "la = la.str.strip('$')\n",
    "\n",
    "la = la.str.replace(',', '')\n",
    "\n",
    "la = la.astype('float64')\n",
    "\n",
    "tape['weight'] = la / la.sum()\n",
    "\n",
    "fa = fa.str.strip('$')\n",
    "\n",
    "fa = fa.str.replace(',', '')\n",
    "\n",
    "fa = fa.astype('float64')\n",
    "\n",
    "arv = arv.str.strip('$')\n",
    "\n",
    "arv = arv.str.replace(',', '')\n",
    "\n",
    "arv = arv.astype('float64')\n",
    "\n",
    "ltv = ltv.str.rstrip('%')\n",
    "\n",
    "ltv = ltv.astype('float64') / 100\n",
    "\n",
    "weight = tape['weight']\n",
    "\n",
    "reo_rate = rate[tape['Substatus'] == 'REO']\n",
    "reo_la = la[tape['Substatus'] == 'REO']\n",
    "reo_fa = fa[tape['Substatus'] == 'REO']\n",
    "reo_arv = arv[tape['Substatus'] == 'REO']\n",
    "reo_ltv = ltv[tape['Substatus'] == 'REO']\n",
    "reo_loans = loans[tape['Substatus'] == 'REO']\n",
    "\n",
    "tape['reo_weight'] = reo_la / reo_la.sum()\n",
    "\n",
    "reo_weight = tape['reo_weight']\n",
    "\n",
    "nreo_rate = rate[(tape['Substatus'] != 'REO') & (tape['Substatus'] != 'Foreclosure')]\n",
    "nreo_la = la[(tape['Substatus'] != 'REO') & (tape['Substatus'] != 'Foreclosure')]\n",
    "nreo_fa = fa[(tape['Substatus'] != 'REO') & (tape['Substatus'] != 'Foreclosure')]\n",
    "nreo_arv = arv[(tape['Substatus'] != 'REO') & (tape['Substatus'] != 'Foreclosure')]\n",
    "nreo_ltv = ltv[(tape['Substatus'] != 'REO') & (tape['Substatus'] != 'Foreclosure')]\n",
    "nreo_loans = loans[(tape['Substatus'] != 'REO') & (tape['Substatus'] != 'Foreclosure')]\n",
    "\n",
    "tape['nreo_weight'] = nreo_la / nreo_la.sum()\n",
    "\n",
    "nreo_weight = tape['nreo_weight']\n",
    "\n",
    "fc_rate = rate[tape['Substatus'] == 'Foreclosure']\n",
    "fc_la = la[tape['Substatus'] == 'Foreclosure']\n",
    "fc_fa = fa[tape['Substatus'] == 'Foreclosure']\n",
    "fc_arv = arv[tape['Substatus'] == 'Foreclosure']\n",
    "fc_ltv = ltv[tape['Substatus'] == 'Foreclosure']\n",
    "fc_loans = loans[tape['Substatus'] == 'Foreclosure']\n",
    "\n",
    "tape['fc_weight'] = fc_la / fc_la.sum()\n",
    "\n",
    "fc_weight = tape['fc_weight']\n",
    "\n",
    "weighted_ltv = ltv * weight\n",
    "\n",
    "weighted_reo_ltv = reo_ltv * reo_weight\n",
    "\n",
    "weighted_nreo_ltv = nreo_ltv * nreo_weight\n",
    "\n",
    "weighted_fc_ltv = fc_ltv * fc_weight\n",
    "\n",
    "wa_ltv = weighted_ltv.sum()\n",
    "\n",
    "wa_reo_ltv = weighted_reo_ltv.sum()\n",
    "\n",
    "wa_nreo_ltv = weighted_nreo_ltv.sum()\n",
    "\n",
    "wa_fc_ltv = weighted_fc_ltv.sum()\n",
    "\n",
    "ha_ltv = la.sum() / arv.sum()\n",
    "\n",
    "ha_reo_ltv = reo_la.sum() / reo_arv.sum()\n",
    "\n",
    "ha_nreo_ltv = nreo_la.sum() / nreo_arv.sum()\n",
    "\n",
    "ha_fc_ltv = fc_la.sum() / fc_arv.sum()\n",
    "\n",
    "total_per = loans.count() / loans.count()\n",
    "\n",
    "nreo_per = nreo_loans.count() / loans.count()\n",
    "\n",
    "reo_per = reo_loans.count() / loans.count()\n",
    "\n",
    "fc_per = fc_loans.count() / loans.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tape3 = pd.concat([nreo_loans, nreo_la, nreo_arv, nreo_ltv], axis=1).set_index('Loan')\n",
    "\n",
    "hilo = tape3[(tape3.LTV > .7) | (tape3.LTV <= .5)] \n",
    "\n",
    "display(hilo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def ecdf(data):\n",
    "    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n",
    "    # Number of data points: n\n",
    "    n = len(data)\n",
    "\n",
    "    # x-data for the ECDF: x\n",
    "    x = np.sort(data)\n",
    "\n",
    "    # y-data for the ECDF: y\n",
    "    y = np.arange(1, n+1) / n\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x_r, y_r = ecdf(tape3.LTV)\n",
    "\n",
    "tape3['avg_ltv'] = tape3.LTV.mean()\n",
    "tape3['med_ltv'] = tape3.LTV.median()\n",
    "tape3['gmean_ltv'] = gmean(tape3.LTV)\n",
    "tape3['hmean_ltv'] = tape3['Loan Amount'].sum() / tape3['ARV'].sum()\n",
    "tape3['x'] = x_r\n",
    "tape3['y'] = y_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = tape3.drop(['Loan Amount', 'ARV'], axis=1)\n",
    "t.set_index('x', inplace=True)\n",
    "sns.set_context('talk')\n",
    "\n",
    "med = 'Median of {0:.2f}%'.format(t.med_ltv.mean() * 100)\n",
    "whm = 'Weighted Harmonic Average of\\n {0:.2f}%'.format(t.hmean_ltv.mean() * 100)\n",
    "maxltv = 'Max LTV of {0:.2f}%'.format(t.LTV.max() * 100)\n",
    "minltv = 'Min LTV of {0:.2f}%'.format(t.LTV.min() * 100)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.plot(t.index, t.y, label='LTV', marker='.', linestyle='none')\n",
    "plt.plot(t.med_ltv, t.y, label='Median: {0:.2f}%'.format(t.med_ltv.max()*100))\n",
    "plt.plot(t.avg_ltv, t.y, label='Average:{0:.2f}%'.format(t.avg_ltv.max()*100))\n",
    "plt.plot(t.gmean_ltv, t.y, label='Geometric Average: {0:.2f}%'.format(t.gmean_ltv.max()*100))\n",
    "plt.plot(t.hmean_ltv, t.y, label='Weighted Harmonic Average: {0:.2f}%'.format(t.hmean_ltv.max()*100))\n",
    "plt.title('April 2018 LTV by Loan')\n",
    "plt.legend()\n",
    "plt.annotate(med, xy=[.7, .1])\n",
    "plt.annotate(whm, xy=[.3, .65])\n",
    "plt.annotate(minltv, xy=[.1, .03])\n",
    "plt.annotate(maxltv, xy=[.8, .95])\n",
    "plt.xticks(np.arange(0,1.1,0.1), ['0', '10%', '20%', '30%', '40%', '50%', '60%', '70%', '80%', '90%', '100%'])\n",
    "plt.yticks(np.arange(0,1.1,0.1), ['0', '10%', '20%', '30%', '40%', '50%', '60%', '70%', '80%', '90%', '100%'])\n",
    "plt.ylabel('Percent of Loans with LTV <= x')\n",
    "plt.xlabel('LTV')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.LTV[t['LTV'] == .7].count() / t.LTV.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$LTV_{WHM} = \\frac{\\displaystyle\\sum_{i=1}^{N}w_i}{\\displaystyle\\sum_{i=1}^{N}{\\left[w_i \\cdot \\frac{LV}{ARV}\\right]}} =  \\frac{\\displaystyle\\sum_{i=1}^{N}\\left[LV_i\\right]}{\\displaystyle\\sum_{i=1}^{N}\\left[ARV_i\\right]} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmtape = tape3.drop(['LTV', 'avg_ltv', 'med_ltv', 'gmean_ltv', 'hmean_ltv', 'x', 'y'], axis=1)\n",
    "hmtape.columns = ['LA', 'ARV']\n",
    "hmtape.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmtape['LTV'] = hmtape.LA / hmtape.ARV\n",
    "hmtape['w'] = hmtape.LA / hmtape.LA.sum()\n",
    "hmtape['wLTV'] = hmtape.LTV * hmtape.w\n",
    "hmtape['recipLTV'] = hmtape.ARV / hmtape.LA\n",
    "hmtape['wrecip'] = hmtape.w * hmtape.recipLTV\n",
    "\n",
    "hmtape.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmtape.w.sum() / hmtape.wrecip.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmtape.LA.sum() / hmtape.ARV.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
